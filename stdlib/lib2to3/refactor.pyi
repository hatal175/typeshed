import logging
import multiprocessing
from typing import Any, Container, Dict, Iterable, Iterator, List, Mapping, NoReturn, Optional, Tuple

from . import btm_matcher as bm, pygram as pygram, pytree as pytree
from .fixer_base import BaseFix
from .fixer_util import find_root as find_root
from .pgen2 import driver as driver, token as token, tokenize as tokenize
from .pgen2.grammar import Grammar

def get_all_fix_names(fixer_pkg: str, remove_prefix: bool = ...) -> List[str]: ...

class _EveryNode(Exception): ...

def get_fixers_from_package(pkg_name: str) -> List[str]: ...

class FixerError(Exception): ...

class RefactoringTool:
    CLASS_PREFIX: str = ...
    FILE_PREFIX: str = ...
    fixers: Iterable[str] = ...
    explicit: Container[str] = ...
    options: Mapping[str, Any] = ...
    grammar: Grammar = ...
    write_unchanged_files: bool = ...
    errors: List[Tuple[str, List[Any], Dict[str, Any]]] = ...
    logger: logging.Logger = ...
    fixer_log: List[str] = ...
    wrote: bool = ...
    driver: driver.Driver = ...  # noqa
    files: List[str] = ...
    BM: bm.BottomMatcher = ...
    bmi_pre_order: List[BaseFix] = ...
    bmi_post_order: List[BaseFix] = ...
    bmi_pre_order_heads: Dict[int, List[BaseFix]] = ...
    bmi_post_order_heads: Dict[int, List[BaseFix]] = ...
    def __init__(
        self, fixer_names: Iterable[str], options: Optional[Mapping[str, Any]] = ..., explicit: Optional[Container[str]] = ...
    ) -> None: ...
    def get_fixers(self) -> Tuple[List[BaseFix], List[BaseFix]]: ...
    def log_error(self, msg: str, *args: Any, **kwds: Any) -> None: ...
    def log_message(self, msg: str, *args: Any) -> None: ...
    def log_debug(self, msg: str, *args: Any) -> None: ...
    def print_output(self, old_text: str, new_text: str, filename: str, equal: bool) -> None: ...
    def refactor(self, items: Iterable[str], write: bool = ..., doctests_only: bool = ...) -> None: ...
    def refactor_dir(self, dir_name: str, write: bool = ..., doctests_only: bool = ...) -> None: ...
    def refactor_file(self, filename: str, write: bool = ..., doctests_only: bool = ...) -> None: ...
    def refactor_string(self, data: str, name: str) -> Optional[pytree._NL]: ...
    def refactor_stdin(self, doctests_only: bool = ...) -> None: ...
    def refactor_tree(self, tree: pytree._NL, name: str) -> bool: ...
    def traverse_by(self, fixers: Mapping[int, List[BaseFix]], traversal: Iterator[pytree._NL]) -> None: ...
    def processed_file(
        self, new_text: str, filename: str, old_text: Optional[str] = ..., write: bool = ..., encoding: Optional[str] = ...
    ) -> None: ...
    def write_file(self, new_text: str, filename: str, old_text: str, encoding: Optional[str] = ...) -> None: ...
    PS1: str = ...
    PS2: str = ...
    def refactor_docstring(self, input: str, filename: str) -> str: ...
    def refactor_doctest(self, block: List[str], lineno: int, indent: str, filename: str) -> List[str]: ...
    def summarize(self) -> None: ...
    def parse_block(self, block: Iterable[str], lineno: int, indent: str) -> pytree._NL: ...
    def wrap_toks(self, block: Iterable[str], lineno: int, indent: str) -> Iterator[tokenize._TokenInfo]: ...
    def gen_lines(self, block: Iterable[str], indent: str) -> Iterator[str]: ...

class MultiprocessingUnsupported(Exception): ...

class MultiprocessRefactoringTool(RefactoringTool):
    queue: Optional[multiprocessing.JoinableQueue] = ...
    output_lock: Optional[multiprocessing._LockLike] = ...
    def __init__(
        self, fixer_names: Iterable[str], options: Optional[Mapping[str, Any]] = ..., explicit: Container[str] = ...
    ) -> None: ...
    def refactor(self, items: Iterable[str], write: bool = ..., doctests_only: bool = ..., num_processes: int = ...) -> None: ...
    def refactor_file(self, filename: str, write: bool = ..., doctests_only: bool = ...) -> None: ...
